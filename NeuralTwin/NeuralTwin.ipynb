{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dff7542b308f41de8f2262963ab0ca97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a114671a1114c06addee1ab67a1ddf1",
              "IPY_MODEL_c690eca7aa2242a79266bee6cf589afa",
              "IPY_MODEL_14f8464bf66a434f8ae5c39566ac9a2e"
            ],
            "layout": "IPY_MODEL_8c0f0907333d40aa927a4537acdb6952"
          }
        },
        "1a114671a1114c06addee1ab67a1ddf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c45dba9952964e9bbf4e14c1777a1cfb",
            "placeholder": "​",
            "style": "IPY_MODEL_47ab45f70d3b414382f181aceffa463d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c690eca7aa2242a79266bee6cf589afa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e62a805b7bd446c98e76cfebe459c07b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f316d304b8e45c68f2fc9c7226080c4",
            "value": 2
          }
        },
        "14f8464bf66a434f8ae5c39566ac9a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ae346286af94e93a5e874ca2b115278",
            "placeholder": "​",
            "style": "IPY_MODEL_cdfd86b828c0468199541b980b9f02fe",
            "value": " 2/2 [01:33&lt;00:00, 43.59s/it]"
          }
        },
        "8c0f0907333d40aa927a4537acdb6952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c45dba9952964e9bbf4e14c1777a1cfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47ab45f70d3b414382f181aceffa463d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e62a805b7bd446c98e76cfebe459c07b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f316d304b8e45c68f2fc9c7226080c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ae346286af94e93a5e874ca2b115278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdfd86b828c0468199541b980b9f02fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 7778446,
          "sourceType": "datasetVersion",
          "datasetId": 4551622
        },
        {
          "sourceId": 7791794,
          "sourceType": "datasetVersion",
          "datasetId": 4561072
        }
      ],
      "dockerImageVersionId": 30665,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "* Parsing conversations\n",
        "\n"
      ],
      "metadata": {
        "id": "1xTt4jOjWlfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install telethon"
      ],
      "metadata": {
        "id": "R2QNjr7vxC3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import configparser\n",
        "import json\n",
        "import asyncio\n",
        "from datetime import date, datetime\n",
        "\n",
        "from telethon.tl.patched import Message\n",
        "from telethon import TelegramClient\n",
        "from telethon.errors import SessionPasswordNeededError\n",
        "from telethon.tl.functions.messages import GetHistoryRequest\n",
        "from telethon.tl.types import PeerChannel"
      ],
      "metadata": {
        "id": "a9CorHOr8jiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading Configs\n",
        "config = configparser.ConfigParser()\n",
        "config.read(\"config.ini\")"
      ],
      "metadata": {
        "id": "LSSnP07C8efm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting configuration values\n",
        "api_id = config['Telegram']['api_id']\n",
        "api_hash = config['Telegram']['api_hash']\n",
        "phone = config['Telegram']['phone']\n",
        "username = config['Telegram']['username']"
      ],
      "metadata": {
        "id": "Tj4RnOZ389bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the client and connect\n",
        "client = TelegramClient(username, api_id, api_hash)"
      ],
      "metadata": {
        "id": "ynmdkXfP9F20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scrapping telegram dialogs function\n",
        "import re\n",
        "\n",
        "def remove_emojis(text):\n",
        "    # Unicode ranges for emojis\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "conversations = []\n",
        "\n",
        "async def main(phone):\n",
        "    await client.start()\n",
        "    print(\"Client Created\")\n",
        "\n",
        "    if not await client.is_user_authorized():\n",
        "        await client.send_code_request(phone)\n",
        "        try:\n",
        "            await client.sign_in(phone, input('Enter the code: '))\n",
        "        except SessionPasswordNeededError:\n",
        "            await client.sign_in(password=input('Password: '))\n",
        "\n",
        "    async with client:\n",
        "        for dialog in await client.get_dialogs():\n",
        "            if dialog.is_user and not dialog.entity.bot and not dialog.is_group and dialog.id != 766015334: # Ban saved messages and block chat with yourself\n",
        "                print(f\"Processing {dialog.name} with ID {dialog.id}\")\n",
        "                offset_id = 0\n",
        "                limit = 100\n",
        "\n",
        "                while True:\n",
        "                    print(f\"Current Offset ID is: {offset_id}\")\n",
        "                    history = await client(GetHistoryRequest(\n",
        "                        peer=dialog.entity,\n",
        "                        offset_id=offset_id,\n",
        "                        offset_date=None,\n",
        "                        add_offset=0,\n",
        "                        limit=limit,\n",
        "                        max_id=0,\n",
        "                        min_id=0,\n",
        "                        hash=0\n",
        "                    ))\n",
        "\n",
        "                    if not history.messages:\n",
        "                        break\n",
        "\n",
        "                    messages = history.messages\n",
        "\n",
        "                    beginConversation = True\n",
        "                    myMessagesCount = 0\n",
        "                    peerCount = 0\n",
        "                    conversation = []\n",
        "                    for _message in messages[::-1]:\n",
        "                        if isinstance(_message, Message) and len(_message.message) != 0:\n",
        "\n",
        "                            if beginConversation:\n",
        "\n",
        "                                if _message.out is False:\n",
        "                                    text = remove_emojis(_message.message).strip()\n",
        "                                    if len(text) > 0:\n",
        "                                        beginConversation = False\n",
        "                                        peerCount += 1\n",
        "                                        conversation.append({'role': 'user', 'content': text})\n",
        "                                    else:\n",
        "                                        continue\n",
        "                                else:\n",
        "                                    continue\n",
        "\n",
        "                            else:\n",
        "\n",
        "                                if myMessagesCount < 2 or peerCount < 2:\n",
        "\n",
        "                                    if _message.out is True:\n",
        "                                        role = 'assistant'\n",
        "                                        myMessagesCount += 1\n",
        "                                    else:\n",
        "                                        role = 'user'\n",
        "                                        peerCount += 1\n",
        "\n",
        "                                    text = remove_emojis(_message.message).strip()\n",
        "                                    conversation.append({'role': role, 'content': text})\n",
        "\n",
        "                                else:\n",
        "                                    print(conversation)\n",
        "                                    conversations.append(conversation)\n",
        "                                    myMessagesCount = 0\n",
        "                                    peerCount = 0\n",
        "                                    beginConversation = True\n",
        "                                    conversation = []\n",
        "                    if len(conversation) != 0: conversations.append(conversation)\n",
        "                    offset_id = messages[len(messages) - 1].id\n"
      ],
      "metadata": {
        "id": "6WSvoJlo9NQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scrapping telegram dialogs (result in \"conversations\")\n",
        "await main(phone)"
      ],
      "metadata": {
        "id": "AkJe1rMnA_A-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving scraped messages\n",
        "with open('conversationsNew.json', 'w') as outfile:\n",
        "    json.dump(conversations, outfile)"
      ],
      "metadata": {
        "id": "Pt-e5DZEI6hI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* PEFT"
      ],
      "metadata": {
        "id": "eCYK_tmrXqOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet transformers==4.34.1 accelerate==0.24.0 sentencepiece==0.1.99 optimum==1.13.2 peft==0.5.0 bitsandbytes==0.41.2.post2 trl==0.7.4"
      ],
      "metadata": {
        "id": "1dXw53h3XtrC",
        "execution": {
          "iopub.status.busy": "2024-03-08T09:51:54.013177Z",
          "iopub.execute_input": "2024-03-08T09:51:54.014072Z",
          "iopub.status.idle": "2024-03-08T09:52:08.886301Z",
          "shell.execute_reply.started": "2024-03-08T09:51:54.014034Z",
          "shell.execute_reply": "2024-03-08T09:52:08.885005Z"
        },
        "trusted": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -- quiet transformers -U  <-- May be required if you have transformers error"
      ],
      "metadata": {
        "id": "W6ELq-E2mahr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
        "from peft import LoraConfig, PeftConfig\n",
        "from trl import SFTTrainer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers"
      ],
      "metadata": {
        "id": "WExbSR6DCevO",
        "execution": {
          "iopub.status.busy": "2024-03-08T09:52:31.851186Z",
          "iopub.execute_input": "2024-03-08T09:52:31.851611Z",
          "iopub.status.idle": "2024-03-08T09:52:51.304196Z",
          "shell.execute_reply.started": "2024-03-08T09:52:31.851579Z",
          "shell.execute_reply": "2024-03-08T09:52:51.303196Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc6ef73a-a128-4231-d2d5-0624ef183276"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading a model\n",
        "model_name = 'mistralai/Mistral-7B-Instruct-v0.1'\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name, device_map='auto', low_cpu_mem_usage=True, offload_state_dict=True,\n",
        "    load_in_4bit=True, torch_dtype=torch.float32,  # weights are 4-bit; layernorms and activations are fp32\n",
        ")\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad=False\n",
        "model.gradient_checkpointing_enable()\n",
        "model.enable_input_require_grads()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "dff7542b308f41de8f2262963ab0ca97",
            "1a114671a1114c06addee1ab67a1ddf1",
            "c690eca7aa2242a79266bee6cf589afa",
            "14f8464bf66a434f8ae5c39566ac9a2e",
            "8c0f0907333d40aa927a4537acdb6952",
            "c45dba9952964e9bbf4e14c1777a1cfb",
            "47ab45f70d3b414382f181aceffa463d",
            "e62a805b7bd446c98e76cfebe459c07b",
            "7f316d304b8e45c68f2fc9c7226080c4",
            "6ae346286af94e93a5e874ca2b115278",
            "cdfd86b828c0468199541b980b9f02fe",
            "7ad9e5ec35be4fa7a32e8bc235f119dd",
            "815cd904dd734eab932d6bc5ca51038d",
            "a63bfd9248fe43f9b6b3bf65a171d4e0",
            "eb128544966c4e0babc5ce49d1f2a6d1",
            "3de2d90bfdb84cc58d70eba6655f8fc2",
            "345e37763bac4a5db27b83bbac590268",
            "35c945a6254944d38ffedb1ce111cfdb"
          ]
        },
        "id": "-6Y8pHBqQLy3",
        "outputId": "172f1608-b235-4f69-d180-e809dfb893cd",
        "execution": {
          "iopub.status.busy": "2024-03-08T09:40:51.484212Z",
          "iopub.execute_input": "2024-03-08T09:40:51.484583Z",
          "iopub.status.idle": "2024-03-08T09:43:15.177329Z",
          "shell.execute_reply.started": "2024-03-08T09:40:51.484544Z",
          "shell.execute_reply": "2024-03-08T09:43:15.176486Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ad9e5ec35be4fa7a32e8bc235f119dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)fetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "815cd904dd734eab932d6bc5ca51038d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a63bfd9248fe43f9b6b3bf65a171d4e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb128544966c4e0babc5ce49d1f2a6d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3de2d90bfdb84cc58d70eba6655f8fc2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "345e37763bac4a5db27b83bbac590268"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35c945a6254944d38ffedb1ce111cfdb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer from vanilla Mistral-7B\n",
        "tokenizer = AutoTokenizer.from_pretrained('mistralai/Mistral-7B-v0.1')\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = 'right'"
      ],
      "metadata": {
        "id": "mYZr1ZhrJ8y0",
        "execution": {
          "iopub.status.busy": "2024-03-08T10:00:42.688188Z",
          "iopub.execute_input": "2024-03-08T10:00:42.688587Z",
          "iopub.status.idle": "2024-03-08T10:00:42.888114Z",
          "shell.execute_reply.started": "2024-03-08T10:00:42.688558Z",
          "shell.execute_reply": "2024-03-08T10:00:42.887213Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "q2iUV2EVKCPr",
        "outputId": "9c045fac-3880-4b4d-9b98-d4f4e67f8e70",
        "execution": {
          "iopub.status.busy": "2024-03-08T10:00:57.192635Z",
          "iopub.execute_input": "2024-03-08T10:00:57.193035Z",
          "iopub.status.idle": "2024-03-08T10:00:57.200511Z",
          "shell.execute_reply.started": "2024-03-08T10:00:57.193005Z",
          "shell.execute_reply": "2024-03-08T10:00:57.199446Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'cuda:0'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving conversations\n",
        "import json\n",
        "import random\n",
        "\n",
        "with open('YOUR PATH TO JSON CONVERSATIONS PATH', 'r') as file:\n",
        "    conversations = json.load(file)\n",
        "\n",
        "selected_conversations = random.sample(conversations, 2000)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-08T01:29:23.497749Z",
          "iopub.execute_input": "2024-03-08T01:29:23.498030Z",
          "iopub.status.idle": "2024-03-08T01:29:23.847107Z",
          "shell.execute_reply.started": "2024-03-08T01:29:23.497996Z",
          "shell.execute_reply": "2024-03-08T01:29:23.846322Z"
        },
        "trusted": true,
        "id": "vVNoL88bIegU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement a dataset class (download data from json if needed)\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, conversations, tokenizer):\n",
        "        self.conversations = conversations\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        conversation = self.conversations[index]\n",
        "        bos = '<|im_start|>'\n",
        "        eos = '<|im_end|>\\n'\n",
        "\n",
        "        finalPrompt = '<|im_start|>system\\nТы студент из Москвы, тебе 20 лет. Ты - моя копия, отвечай моим друзяьми на их сообщения в социальной сети.\\n<|im_end|>\\n'\n",
        "        for message in conversation:\n",
        "            if message['role'] == 'user':\n",
        "                finalPrompt += bos + 'friend\\n' + message['content'] + eos\n",
        "            else:\n",
        "                finalPrompt += bos + 'you\\n' + message['content'] + eos\n",
        "\n",
        "\n",
        "        tokenized_input = self.tokenizer(finalPrompt, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "        return {key: val.squeeze(0) for key, val in tokenized_input.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.conversations)\n"
      ],
      "metadata": {
        "id": "aOVWmh-b1c5I",
        "execution": {
          "iopub.status.busy": "2024-03-08T01:33:06.850629Z",
          "iopub.execute_input": "2024-03-08T01:33:06.851028Z",
          "iopub.status.idle": "2024-03-08T01:33:06.859801Z",
          "shell.execute_reply.started": "2024-03-08T01:33:06.850998Z",
          "shell.execute_reply": "2024-03-08T01:33:06.858801Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dataset\n",
        "train_data = Dataset(conversations, tokenizer)"
      ],
      "metadata": {
        "id": "Q9bzDgQrRgZH",
        "execution": {
          "iopub.status.busy": "2024-03-08T01:33:12.078667Z",
          "iopub.execute_input": "2024-03-08T01:33:12.079038Z",
          "iopub.status.idle": "2024-03-08T01:33:12.083581Z",
          "shell.execute_reply.started": "2024-03-08T01:33:12.079012Z",
          "shell.execute_reply": "2024-03-08T01:33:12.082406Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting congifurations for training\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=4,\n",
        "    lora_dropout=0.05,\n",
        "    r=8,\n",
        "    bias=\"none\",\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\"],\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=\"logs\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=8,\n",
        "    gradient_accumulation_steps=1, # 4\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_steps=0,\n",
        "    logging_steps=25,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.001,\n",
        "    max_grad_norm=0.3,\n",
        "    max_steps=-1,\n",
        "    warmup_ratio=0.03,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    report_to=None,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=None,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing=False,\n",
        "    max_seq_length=1024\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-08T01:33:23.152880Z",
          "iopub.execute_input": "2024-03-08T01:33:23.153840Z",
          "iopub.status.idle": "2024-03-08T01:33:23.316068Z",
          "shell.execute_reply.started": "2024-03-08T01:33:23.153803Z",
          "shell.execute_reply": "2024-03-08T01:33:23.315120Z"
        },
        "trusted": true,
        "id": "Iwp2Glm0IegU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "trainer.train()"
      ],
      "metadata": {
        "trusted": true,
        "id": "k-j-Q6JcIegV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving model\n",
        "trainer.model.save_pretrained('YOUR PATH TO SAVE THE MODEL')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-08T01:36:42.157426Z",
          "iopub.execute_input": "2024-03-08T01:36:42.157903Z",
          "iopub.status.idle": "2024-03-08T01:36:42.238138Z",
          "shell.execute_reply.started": "2024-03-08T01:36:42.157870Z",
          "shell.execute_reply": "2024-03-08T01:36:42.237146Z"
        },
        "trusted": true,
        "id": "fqxmC9tqIegV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison section"
      ],
      "metadata": {
        "id": "80IxqYEnIegV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmsquOQKkaiL",
        "outputId": "d2ab42e2-7d7f-4bd2-ef79-2c084d8f6224"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing saved model\n",
        "model_name = 'mistralai/Mistral-7B-Instruct-v0.1'\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map='auto',\n",
        "    low_cpu_mem_usage=True,\n",
        "    offload_state_dict=True,\n",
        "    load_in_4bit=True,\n",
        "    torch_dtype=torch.float32  # weights are 4-bit; layernorms and activations are fp32\n",
        ")\n",
        "\n",
        "model_path = '/content/drive/MyDrive/NLP/NeuralTwinModelWeights'\n",
        "peftModel = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    device_map='auto',\n",
        "    low_cpu_mem_usage=True,\n",
        "    offload_state_dict=True,\n",
        "    load_in_4bit=True,\n",
        "    torch_dtype=torch.float32\n",
        ")\n",
        "\n",
        "peftModel.eval()\n",
        "model.eval()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-08T09:55:33.636961Z",
          "iopub.execute_input": "2024-03-08T09:55:33.637411Z",
          "iopub.status.idle": "2024-03-08T09:58:15.524404Z",
          "shell.execute_reply.started": "2024-03-08T09:55:33.637379Z",
          "shell.execute_reply": "2024-03-08T09:58:15.523401Z"
        },
        "trusted": true,
        "id": "fkR14-aoIegV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer from vanilla Mistral-7B\n",
        "tokenizer = AutoTokenizer.from_pretrained('mistralai/Mistral-7B-v0.1')\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = 'right'\n",
        "\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dj4s6jHer9Au",
        "outputId": "13b8e0b6-01c7-4231-803e-974c32fa4bec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that helps to decode an output from language model\n",
        "def process(outputs):\n",
        "  answers = []\n",
        "  for output in outputs:\n",
        "    index = output.find('<')\n",
        "    if index == 0:\n",
        "      pass\n",
        "    elif index == -1:\n",
        "      answers.append(output)\n",
        "    else:\n",
        "      answers.append(output[:index])\n",
        "  return answers\n",
        "\n",
        "# Function to generate response with prompt\n",
        "def generate_response(prompt, model):\n",
        "  encodedPrompt = tokenizer(prompt, return_tensors='pt', add_special_tokens=False)\n",
        "  modelInputs = encodedPrompt.to(device)\n",
        "\n",
        "  generated_ids = model.generate(**modelInputs, max_new_tokens=100, pad_token_id=tokenizer.eos_token_id)\n",
        "  decoded = tokenizer.batch_decode(generated_ids)\n",
        "\n",
        "  toTraverse = decoded[0][len(prompt):]\n",
        "  answers = process(toTraverse.split('\\n'))\n",
        "  return answers"
      ],
      "metadata": {
        "id": "7HwyigfO3cAQ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts =  [\n",
        "    \"<|im_start|>system\\nТы студент из Москвы, тебе 20 лет. Ты - моя копия, отвечай моим друзяьми на их сообщения в социальной сети.<|im_end|>\\n<|im_start|>friend\\nКак твои дела?<|im_end|>\\n\",\n",
        "    \"<|im_start|>system\\nТы студент из Москвы, тебе 20 лет. Ты - моя копия, отвечай моим друзяьми на их сообщения в социальной сети.<|im_end|>\\n<|im_start|>friend\\nКак тебе вчерашний концерт.<|im_end|>\\n\",\n",
        "    \"<|im_start|>system\\nТы студент из Москвы, тебе 20 лет. Ты - моя копия, отвечай моим друзяьми на их сообщения в социальной сети.<|im_end|>\\n<|im_start|>friend\\nПривет, че делаешь?<|im_end|>\\n\"\n",
        "]\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "table_template = \"\"\"<table style=\"border:1px solid black\" >\n",
        "  <tr>\n",
        "    <th style=\"text-align: center; border:1px solid black\">PROMPT</th>\n",
        "    <th style=\"text-align: center; border:1px solid black\">BEFORE</th>\n",
        "    <th style=\"text-align: center; border:1px solid black\">AFTER</th>\n",
        "  </tr>\n",
        "{}\n",
        "</table>\"\"\"\n",
        "\n",
        "row_template = '''  <tr>\n",
        "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`{}`</pre></td>\n",
        "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
        "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
        "  </tr>'''\n",
        "\n",
        "rows = []\n",
        "\n",
        "for prompt in prompts:\n",
        "\n",
        "    answers_before = generate_response(prompt, model)\n",
        "    answers_after = generate_response(prompt, peftModel)\n",
        "    rows.append(row_template.format(prompt, '\\n'.join(answers_before), '\\n'.join(answers_after)))\n",
        "\n",
        "display(HTML(table_template.format('\\n'.join(rows))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "-hSNqUHY2a0r",
        "outputId": "1df67b65-b07f-4f34-c120-888e1c28839c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table style=\"border:1px solid black\" >\n",
              "  <tr>\n",
              "    <th style=\"text-align: center; border:1px solid black\">PROMPT</th>\n",
              "    <th style=\"text-align: center; border:1px solid black\">BEFORE</th>\n",
              "    <th style=\"text-align: center; border:1px solid black\">AFTER</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`<|im_start|>system\n",
              "Ты студент из Москвы, тебе 20 лет. Ты - моя копия, отвечай моим друзяьми на их сообщения в социальной сети.<|im_end|>\n",
              "<|im_start|>friend\n",
              "Как твои дела?<|im_end|>\n",
              "`</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">Все хорошо, спасибо. Я учился в университете, но теперь я работаю в компании.\n",
              "Какую компанию?\n",
              "Моя компания специализируется на разработке программ.</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">Нормально\n",
              "Я сдал\n",
              "Ахахахахахахахахахахахахахахахахахахахахахахахахахахахахахахахахахахахахахахахахахахахахахахахаха</pre></td>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`<|im_start|>system\n",
              "Ты студент из Москвы, тебе 20 лет. Ты - моя копия, отвечай моим друзяьми на их сообщения в социальной сети.<|im_end|>\n",
              "<|im_start|>friend\n",
              "Как тебе вчерашний концерт.<|im_end|>\n",
              "`</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">Ты помнишь, что я смотрел концерт группы \"The Beatles\" в 1964 году.\n",
              "Ты помнишь, что я смотрел концерт группы \"The Beatles\" в 1964 году.</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">Не помню\n",
              "Но я помню что ты сказал что он был\n",
              "Ты сказал что он был\n",
              "Ты сказал что он был</pre></td>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`<|im_start|>system\n",
              "Ты студент из Москвы, тебе 20 лет. Ты - моя копия, отвечай моим друзяьми на их сообщения в социальной сети.<|im_end|>\n",
              "<|im_start|>friend\n",
              "Привет, че делаешь?<|im_end|>\n",
              "`</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">Что делаешь, друг?\n",
              "Не помню, что ты делаешь.\n",
              "Я учился в университете.\n",
              "Что ты учился?</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">Да я вчера сдал\n",
              "А сегодня уже нет\n",
              "Я вчера сдал\n",
              "А сегодня уже нет</pre></td>\n",
              "  </tr>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}